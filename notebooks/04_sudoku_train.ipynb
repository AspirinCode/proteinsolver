{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_gnhLD0HvhU",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies (Google Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    GOOGLE_COLAB = True\n",
    "except ImportError:\n",
    "    GOOGLE_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "hIbvKDk_HvhX",
    "outputId": "349cb6d3-ffbc-4550-d9dd-dd6288ed5356"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !pip install --upgrade torch-scatter\n",
    "    !pip install --upgrade torch-sparse\n",
    "    !pip install --upgrade torch-cluster\n",
    "    !pip install --upgrade torch-spline-conv\n",
    "    !pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "tw-y9MmIHvha",
    "outputId": "0666864a-5017-40a1-a77c-d23388eb0b1c"
   },
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    !pip install git+https://gitlab.com/ostrokach/proteinsolver.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoBMUoW2Hvhp",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbKxMUZWHvhq"
   },
   "outputs": [],
   "source": [
    "import atexit\n",
    "import csv\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "rczy7pPiHvhs",
    "outputId": "8e4673d7-4cc7-4f8e-ffc4-de94302e5fab"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'proteinsolver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ace4171f121b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mproteinsolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproteinsolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'proteinsolver'"
     ]
    }
   ],
   "source": [
    "import proteinsolver\n",
    "import proteinsolver.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fFnAyUOHvhv"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsEY3dtLHvhy",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(tempfile.gettempdir())\n",
    "DATA_ROOT = Path(\"/home/strokach/ml_data\")\n",
    "DATA_ROOT.mkdir(exist_ok=True)\n",
    "DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"sudoku_train\"\n",
    "NOTEBOOK_PATH = Path(NOTEBOOK_NAME)\n",
    "NOTEBOOK_PATH.mkdir(exist_ok=True)\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SudokuDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZP3bLDO9PgT9"
   },
   "outputs": [],
   "source": [
    "sudoku_dataset_train = proteinsolver.datasets.SudokuDataset2(root=DATA_ROOT.joinpath(\"sudoku_train\"), subset=\"sudoku_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudoku_dataset_valid = proteinsolver.datasets.SudokuDataset2(root=DATA_ROOT.joinpath(\"sudoku_valid\"), subset=\"sudoku_valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6W1sfkUHr89O"
   },
   "source": [
    "## `TUDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOt0mVyir89P"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "Ctf7-3yYr89S",
    "outputId": "9ab47d4d-5cad-4f36-b32c-0f7b912d0e0a"
   },
   "outputs": [],
   "source": [
    "tu_dataset = TUDataset(root=tempfile.gettempdir() + '/ENZYMES', name='ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tLtEuvRwr89Y",
    "outputId": "ca22011f-8035-4c70-c722-4ed39b1bdc17"
   },
   "outputs": [],
   "source": [
    "tu_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3kWuRaxr89h"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGLXgqYlr89j"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import ChebConv, EdgeConv, GATConv, GCNConv\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops, scatter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72WWaQOXJDdr"
   },
   "outputs": [],
   "source": [
    "class EdgeConvMod(torch.nn.Module):\n",
    "    def __init__(self, nn, aggr=\"max\"):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "        self.aggr = aggr\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.nn)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        \"\"\"\"\"\"\n",
    "        row, col = edge_index\n",
    "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "\n",
    "        # TODO: Try -x[col] instead of x[col] - x[row]\n",
    "        if edge_attr is None:\n",
    "            out = torch.cat([x[row], x[col] - x[row]], dim=-1)\n",
    "        else:\n",
    "            out = torch.cat([x[row], x[col] - x[row], edge_attr], dim=-1)\n",
    "        out = self.nn(out)\n",
    "        x = scatter_(self.aggr, out, row, dim_size=x.size(0))\n",
    "\n",
    "        return x, out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}(nn={})\".format(self.__class__.__name__, self.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDrlxheizsKg"
   },
   "outputs": [],
   "source": [
    "class EdgeConvBatch(nn.Module):\n",
    "    def __init__(self, gnn, hidden_size, batch_norm=True, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gnn = gnn\n",
    "\n",
    "        x_post_modules = []\n",
    "        edge_attr_post_modules = []\n",
    "\n",
    "        if batch_norm is not None:\n",
    "            x_post_modules.append(nn.BatchNorm1d(hidden_size))\n",
    "            edge_attr_post_modules.append(nn.BatchNorm1d(hidden_size))\n",
    "\n",
    "        if dropout:\n",
    "            x_post_modules.append(nn.Dropout(dropout))\n",
    "            edge_attr_post_modules.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.x_postprocess = nn.Sequential(*x_post_modules)\n",
    "        self.edge_attr_postprocess = nn.Sequential(*edge_attr_post_modules)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x, edge_attr = self.gnn(x, edge_index, edge_attr)\n",
    "        x = self.x_postprocess(x)\n",
    "        edge_attr = self.edge_attr_postprocess(edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNCaSlrFDGA6"
   },
   "outputs": [],
   "source": [
    "def get_graph_conv_layer(input_size, hidden_size, output_size):\n",
    "    mlp = nn.Sequential(\n",
    "        #\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, output_size),\n",
    "    )\n",
    "    gnn = EdgeConvMod(nn=mlp, aggr=\"add\")\n",
    "    graph_conv = EdgeConvBatch(gnn, output_size, batch_norm=True, dropout=0.2)\n",
    "    return graph_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNCaSlrFDGA6"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, x_input_size, adj_input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_x = nn.Sequential(\n",
    "            nn.Embedding(x_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        if adj_input_size:\n",
    "            self.embed_adj = nn.Sequential(\n",
    "                nn.BatchNorm1d(adj_input_size),\n",
    "                nn.Linear(adj_input_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            self.embed_adj = None\n",
    "\n",
    "        self.graph_conv_1 = get_graph_conv_layer((2 + bool(adj_input_size)) * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.graph_conv_2 = get_graph_conv_layer(3 * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.graph_conv_3 = get_graph_conv_layer(3 * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.graph_conv_4 = get_graph_conv_layer(3 * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.linear_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "\n",
    "        x = self.embed_x(x)\n",
    "        edge_index, _ = remove_self_loops(edge_index)  # We should remove self loops in this case!\n",
    "        edge_attr = self.embed_adj(edge_attr) if edge_attr is not None else None\n",
    "\n",
    "        x_out, edge_attr_out = self.graph_conv_1(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr = (edge_attr + edge_attr_out) if edge_attr is not None else edge_attr_out\n",
    "\n",
    "        x = F.relu(x)\n",
    "        edge_attr = F.relu(edge_attr)\n",
    "        x_out, edge_attr_out = self.graph_conv_2(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr += edge_attr_out\n",
    "\n",
    "        x = F.relu(x)\n",
    "        edge_attr = F.relu(edge_attr)\n",
    "        x_out, edge_attr_out = self.graph_conv_3(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr += edge_attr_out\n",
    "\n",
    "        x = F.relu(x)\n",
    "        edge_attr = F.relu(edge_attr)\n",
    "        x_out, edge_attr_out = self.graph_conv_4(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr += edge_attr_out\n",
    "\n",
    "        x = self.linear_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fixed_width(lst, precision=None):\n",
    "    lst = [round(l, precision) if isinstance(l, float) else l for l in lst]\n",
    "    return [f\"{l: <18}\" for l in lst]\n",
    "\n",
    "\n",
    "class Stats:\n",
    "    epoch: int\n",
    "    step: int\n",
    "    batch_size: int\n",
    "    echo: bool\n",
    "    total_loss: float\n",
    "    num_correct_preds: int\n",
    "    num_preds: int\n",
    "    num_correct_preds_missing: int\n",
    "    num_preds_missing: int\n",
    "    num_correct_preds_missing_valid: int\n",
    "    num_preds_missing_valid: int\n",
    "    start_time: float\n",
    "\n",
    "    def __init__(self, *, epoch=0, step=0, batch_size=1, filename=None, echo=True):\n",
    "        self.epoch = epoch\n",
    "        self.step = step\n",
    "        self.batch_size = batch_size\n",
    "        self.echo = echo\n",
    "        self.stats_columns = [\n",
    "            \"epoch\",\n",
    "            \"step\",\n",
    "            \"datapoint\",\n",
    "            \"avg_loss\",\n",
    "            \"accuracy\",\n",
    "            \"accuracy_m\",\n",
    "            \"accuracy_mv\",\n",
    "            \"time_elapsed\",\n",
    "        ]\n",
    "        self.reset_parameters()\n",
    "\n",
    "        if filename:\n",
    "            self.filehandle = open(filename, \"wt\", newline=\"\")\n",
    "            self.writer = csv.DictWriter(self.filehandle, list(self.stats.keys()), dialect=\"unix\")\n",
    "            self.writer.writeheader()\n",
    "            atexit.register(self.filehandle.close)\n",
    "        else:\n",
    "            self.filehandle = None\n",
    "            self.writer = None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        try:\n",
    "            self.prev = self.stats\n",
    "        except AttributeError:\n",
    "            self.prev = {}\n",
    "        self.num_steps = 0\n",
    "        self.total_loss = 0\n",
    "        self.num_correct_preds = 0\n",
    "        self.num_preds = 0\n",
    "        self.num_correct_preds_missing = 0\n",
    "        self.num_preds_missing = 0\n",
    "        self.num_correct_preds_missing_valid = 0\n",
    "        self.num_preds_missing_valid = 0\n",
    "        self.start_time = time.perf_counter()\n",
    "\n",
    "    @property\n",
    "    def header(self):\n",
    "        return \"\".join(to_fixed_width(self.stats.keys()))\n",
    "\n",
    "    @property\n",
    "    def row(self):\n",
    "        return \"\".join(to_fixed_width(self.stats.values(), 4))\n",
    "\n",
    "    @property\n",
    "    def stats(self):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return {k: getattr(self, k) for k in self.stats_columns}\n",
    "\n",
    "    @property\n",
    "    def datapoint(self):\n",
    "        return self.step * self.batch_size\n",
    "\n",
    "    @property\n",
    "    def avg_loss(self):\n",
    "        return np.float64(1) * self.total_loss / self.num_steps\n",
    "\n",
    "    @property\n",
    "    def accuracy(self):\n",
    "        return np.float64(1) * self.num_correct_preds / self.num_preds\n",
    "\n",
    "    @property\n",
    "    def accuracy_m(self):\n",
    "        return np.float64(1) * self.num_correct_preds_missing / self.num_preds_missing\n",
    "\n",
    "    @property\n",
    "    def accuracy_mv(self):\n",
    "        return np.float64(1) * self.num_correct_preds_missing_valid / self.num_preds_missing_valid\n",
    "\n",
    "    @property\n",
    "    def time_elapsed(self):\n",
    "        return time.perf_counter() - self.start_time\n",
    "\n",
    "    def write_header(self):\n",
    "        if self.echo:\n",
    "            print(self.header)\n",
    "        if self.writer is not None:\n",
    "            self.writer.writeheader()\n",
    "\n",
    "    def write_row(self):\n",
    "        if self.echo:\n",
    "            print(self.row)\n",
    "        if self.writer is not None:\n",
    "            self.writer.writerow(self.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_on_missing(x, y, output):\n",
    "    mask = (x == 9).squeeze()\n",
    "    if not mask.any():\n",
    "        return 0.0, 0.0\n",
    "    output_missing = output[mask]\n",
    "    _, predicted_missing = torch.max(output_missing.data, 1)\n",
    "    return (predicted_missing == y[mask]).sum().item(), len(predicted_missing)\n",
    "\n",
    "\n",
    "\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def eval_net(net: nn.Module):\n",
    "    training = net.training\n",
    "    try:\n",
    "        net.train(False)\n",
    "        yield\n",
    "    finally:\n",
    "        net.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "info_size = 2_000\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(sudoku_dataset_train, shuffle=True, num_workers=4, batch_size=batch_size, drop_last=True),\n",
    "    \"valid\": DataLoader(\n",
    "        sudoku_dataset_valid[:300], shuffle=False, num_workers=4, batch_size=batch_size, drop_last=False\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6380
    },
    "colab_type": "code",
    "id": "azxPKTSKwcE8",
    "outputId": "09ed9b8b-25b9-49ff-8d02-83a4ec0ecba1"
   },
   "outputs": [],
   "source": [
    "continue_previous = False\n",
    "\n",
    "if not continue_previous:\n",
    "    net = Net(x_input_size=10, adj_input_size=None, hidden_size=128, output_size=9).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"max\", verbose=True)\n",
    "\n",
    "    stats = Stats(epoch=0, step=0, batch_size=batch_size, filename=NOTEBOOK_PATH / \"training.log\", echo=True)\n",
    "    stats.write_header()\n",
    "\n",
    "net = net.train()\n",
    "for epoch in range(stats.epoch + 1 if continue_previous else 0, 100_000):\n",
    "    stats.epoch = epoch\n",
    "    for data in dataloaders[\"train\"]:\n",
    "        stats.step += 1\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "        output = net(data.x, data.edge_index, data.edge_attr if hasattr(data, \"edge_attr\") else None)\n",
    "\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "\n",
    "        stats.total_loss += loss.detach().item()\n",
    "        stats.num_steps += 1\n",
    "\n",
    "        # Accuracy for all\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        stats.num_correct_preds += (predicted == data.y).sum().item()\n",
    "        stats.num_preds += len(predicted)\n",
    "\n",
    "        # Accuracy for missing only\n",
    "        num_correct, num_total = get_stats_on_missing(data.x, data.y, output)\n",
    "        stats.num_correct_preds_missing += num_correct\n",
    "        stats.num_preds_missing += num_total\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (stats.datapoint % info_size) < batch_size:\n",
    "            for j, data in enumerate(dataloaders[\"valid\"]):\n",
    "                data = data.to(device)\n",
    "\n",
    "                with torch.no_grad() and eval_net(net):\n",
    "                    output = net(data.x, data.edge_index, data.edge_attr if hasattr(data, \"edge_attr\") else None)\n",
    "\n",
    "                num_correct, num_total = get_stats_on_missing(data.x, data.y, output)\n",
    "                stats.num_correct_preds_missing_valid += num_correct\n",
    "                stats.num_preds_missing_valid += num_total\n",
    "\n",
    "            stats.write_row()\n",
    "            stats.reset_parameters()\n",
    "\n",
    "    scheduler.step(stats.prev[\"accuracy_mv\"])\n",
    "    output_filename = (\n",
    "        f\"e{stats.epoch}-s{stats.step}-d{stats.datapoint}\"\n",
    "        f\"-amv{str(round(stats.prev['accuracy_mv'], 4)).replace('.', '')}.state\"\n",
    "    )\n",
    "    torch.save(net.state_dict(), NOTEBOOK_PATH.joinpath(output_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1fXJz1l9HvhW",
    "u9q4iTifHvhl"
   ],
   "name": "Copy of 2019-03-30-sudoku-4xEdgeConv-09862+.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:defaults-v1]",
   "language": "python",
   "name": "conda-env-defaults-v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
