{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_gnhLD0HvhU",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fXJz1l9HvhW"
   },
   "source": [
    "### Install `pytorch_geometric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "hIbvKDk_HvhX",
    "outputId": "349cb6d3-ffbc-4550-d9dd-dd6288ed5356"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "tw-y9MmIHvha",
    "outputId": "0666864a-5017-40a1-a77c-d23388eb0b1c"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch-sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "n3SMtaYHHvhc",
    "outputId": "6250a80b-b32d-4fc8-cf90-ad0507e83ab6"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "4AQ_A4XLHvhg",
    "outputId": "601b9d38-8291-431d-a90b-046bb233469a"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch-spline-conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "uk6E9JP_Hvhj",
    "outputId": "5a986a43-4d09-41ab-efb6-9fb1cab56cb7"
   },
   "outputs": [],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9q4iTifHvhl"
   },
   "source": [
    "### Install `proteinsolver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "HCWw1IgNHvhm",
    "outputId": "fcb1a352-1ca8-4708-c3af-11bb0f9a3c57"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://gitlab.com/ostrokach/proteinsolver.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoBMUoW2Hvhp",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "EmCKag-5MCiB",
    "outputId": "40059204-55bf-4285-eb0a-34098e980c40"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbKxMUZWHvhq"
   },
   "outputs": [],
   "source": [
    "import atexit\n",
    "import csv\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "from collections import deque\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy import stats\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import ChebConv, EdgeConv, GATConv, GCNConv\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops, scatter_\n",
    "\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "rczy7pPiHvhs",
    "outputId": "8e4673d7-4cc7-4f8e-ffc4-de94302e5fab"
   },
   "outputs": [],
   "source": [
    "import kmbio\n",
    "from kmbio import PDB\n",
    "from kmtools import structure_tools\n",
    "\n",
    "import proteinsolver\n",
    "import proteinsolver.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fFnAyUOHvhv"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"generate_protein_sequences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = Path(NOTEBOOK_NAME).resolve()\n",
    "NOTEBOOK_PATH.mkdir(exist_ok=True)\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRUCTURE_FILE = Path(os.getenv(\"STRUCTURE_FILE\", NOTEBOOK_PATH / \"inputs\" / \"1n5uA03.pdb\")).resolve()\n",
    "# STRUCTURE_FILE = Path(os.getenv(\"STRUCTURE_FILE\", NOTEBOOK_PATH / \"inputs\" / \"4z8jA00.pdb\")).resolve()\n",
    "# STRUCTURE_FILE = Path(os.getenv(\"STRUCTURE_FILE\", NOTEBOOK_PATH / \"inputs\" / \"4unuA00.pdb\")).resolve()\n",
    "# STRUCTURE_FILE = Path(os.getenv(\"STRUCTURE_FILE\", NOTEBOOK_PATH / \"inputs\" / \"4beuA02.pdb\")).resolve()\n",
    "STRUCTURE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_all = PDB.load(STRUCTURE_FILE)\n",
    "structure = PDB.Structure(STRUCTURE_FILE.name + \"A\", structure_all[0].extract('A'))\n",
    "assert len(list(structure.chains)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB.view_structure(structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3kWuRaxr89h"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72WWaQOXJDdr"
   },
   "outputs": [],
   "source": [
    "class EdgeConvMod(torch.nn.Module):\n",
    "    def __init__(self, nn, aggr=\"max\"):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "        self.aggr = aggr\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.nn)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        \"\"\"\"\"\"\n",
    "        row, col = edge_index\n",
    "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "\n",
    "        # TODO: Try -x[col] instead of x[col] - x[row]\n",
    "        if edge_attr is None:\n",
    "            out = torch.cat([x[row], x[col]], dim=-1)\n",
    "        else:\n",
    "            out = torch.cat([x[row], x[col], edge_attr], dim=-1)\n",
    "        out = self.nn(out)\n",
    "        x = scatter_(self.aggr, out, row, dim_size=x.size(0))\n",
    "\n",
    "        return x, out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}(nn={})\".format(self.__class__.__name__, self.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDrlxheizsKg"
   },
   "outputs": [],
   "source": [
    "class EdgeConvBatch(nn.Module):\n",
    "    def __init__(self, gnn, hidden_size, batch_norm=True, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gnn = gnn\n",
    "\n",
    "        x_post_modules = []\n",
    "        edge_attr_post_modules = []\n",
    "\n",
    "        if batch_norm is not None:\n",
    "            x_post_modules.append(nn.LayerNorm(hidden_size))\n",
    "            edge_attr_post_modules.append(nn.LayerNorm(hidden_size))\n",
    "\n",
    "        if dropout:\n",
    "            x_post_modules.append(nn.Dropout(dropout))\n",
    "            edge_attr_post_modules.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.x_postprocess = nn.Sequential(*x_post_modules)\n",
    "        self.edge_attr_postprocess = nn.Sequential(*edge_attr_post_modules)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        x, edge_attr = self.gnn(x, edge_index, edge_attr)\n",
    "        x = self.x_postprocess(x)\n",
    "        edge_attr = self.edge_attr_postprocess(edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNCaSlrFDGA6"
   },
   "outputs": [],
   "source": [
    "def get_graph_conv_layer(input_size, hidden_size, output_size):\n",
    "    mlp = nn.Sequential(\n",
    "        #\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, output_size),\n",
    "    )\n",
    "    gnn = EdgeConvMod(nn=mlp, aggr=\"add\")\n",
    "    graph_conv = EdgeConvBatch(gnn, output_size, batch_norm=True, dropout=0.2)\n",
    "    return graph_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNCaSlrFDGA6"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, x_input_size, adj_input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_x = nn.Sequential(\n",
    "            nn.Embedding(x_input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        if adj_input_size:\n",
    "            self.embed_adj = nn.Sequential(\n",
    "                nn.Linear(adj_input_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.LayerNorm(hidden_size),\n",
    "#                 nn.ELU(),\n",
    "            )\n",
    "        else:\n",
    "            self.embed_adj = None\n",
    "\n",
    "        self.graph_conv_1 = get_graph_conv_layer((2 + bool(adj_input_size)) * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.graph_conv_2 = get_graph_conv_layer(3 * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.graph_conv_3 = get_graph_conv_layer(3 * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.graph_conv_4 = get_graph_conv_layer(3 * hidden_size, 2 * hidden_size, hidden_size)\n",
    "        self.linear_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "\n",
    "        x = self.embed_x(x)\n",
    "        edge_index, _ = remove_self_loops(edge_index)  # We should remove self loops in this case!\n",
    "        edge_attr = self.embed_adj(edge_attr) if edge_attr is not None else None\n",
    "\n",
    "        x_out, edge_attr_out = self.graph_conv_1(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr = (edge_attr + edge_attr_out) if edge_attr is not None else edge_attr_out\n",
    "\n",
    "        x = F.relu(x)\n",
    "        edge_attr = F.relu(edge_attr)\n",
    "        x_out, edge_attr_out = self.graph_conv_2(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr += edge_attr_out\n",
    "\n",
    "        x = F.relu(x)\n",
    "        edge_attr = F.relu(edge_attr)\n",
    "        x_out, edge_attr_out = self.graph_conv_3(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr += edge_attr_out\n",
    "\n",
    "        x = F.relu(x)\n",
    "        edge_attr = F.relu(edge_attr)\n",
    "        x_out, edge_attr_out = self.graph_conv_4(x, edge_index, edge_attr)\n",
    "        x += x_out\n",
    "        edge_attr += edge_attr_out\n",
    "\n",
    "        x = self.linear_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6380
    },
    "colab_type": "code",
    "id": "azxPKTSKwcE8",
    "outputId": "09ed9b8b-25b9-49ff-8d02-83a4ec0ecba1"
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def eval_net(net: nn.Module):\n",
    "    training = net.training\n",
    "    try:\n",
    "        net.train(False)\n",
    "        yield\n",
    "    finally:\n",
    "        net.train(training)\n",
    "\n",
    "\n",
    "def get_stats_on_missing(data, output):\n",
    "    mask = (data.x == num_features).squeeze()\n",
    "    output_missing = output[mask]\n",
    "    _, predicted_missing = torch.max(output_missing.data, 1)\n",
    "    return (predicted_missing == data.y[mask]).sum().item(), len(predicted_missing)\n",
    "\n",
    "\n",
    "def get_data_x(data, frac_present):\n",
    "    x = torch.where(\n",
    "        torch.rand(data.y.size(0), device=data.y.device) < frac_present,\n",
    "        data.y,\n",
    "        torch.ones(1, dtype=torch.long, device=data.y.device) * num_features,\n",
    "    )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "device = torch.device(\"cuda:0\")\n",
    "# device = \"cpu\"\n",
    "batch_size = 4\n",
    "num_features = 20\n",
    "adj_input_size = 2\n",
    "hidden_size = 128\n",
    "frac_present = 0.5\n",
    "frac_present_valid = frac_present\n",
    "info_size= 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(\n",
    "    x_input_size=num_features + 1, adj_input_size=adj_input_size, hidden_size=hidden_size, output_size=num_features\n",
    ")\n",
    "net.load_state_dict(torch.load(\"protein_4xEdgeConv_bs4/e12-s1652709-d6610836.state\"))\n",
    "net.eval()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinData(NamedTuple):\n",
    "    sequence: str\n",
    "    row_index: torch.LongTensor\n",
    "    col_index: torch.LongTensor\n",
    "    distances: torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_dataset_wdistances(structure_file, model_id, chain_id, r_cutoff=12):\n",
    "    structure = PDB.load(structure_file)\n",
    "    chain = structure[0][chain_id]\n",
    "    num_residues = len(list(chain.residues))\n",
    "    dd = structure_tools.DomainDef(model_id, chain_id, 1, num_residues)\n",
    "    domain = structure_tools.extract_domain(structure, [dd])\n",
    "    distances_core = structure_tools.get_distances(domain, r_cutoff, 0, groupby=\"residue\")\n",
    "    assert (distances_core[\"residue_idx_1\"] <= distances_core[\"residue_idx_2\"]).all()\n",
    "    return domain, distances_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seq_and_adj(structure_file, chain_id):\n",
    "    domain, result_df = get_interaction_dataset_wdistances(structure_file, 0, chain_id, r_cutoff=12)\n",
    "    domain_sequence = structure_tools.get_chain_sequence(domain)\n",
    "    assert max(result_df[\"residue_idx_1\"].values) < len(domain_sequence)\n",
    "    assert max(result_df[\"residue_idx_2\"].values) < len(domain_sequence)\n",
    "    data = ProteinData(\n",
    "        domain_sequence,\n",
    "        result_df[\"residue_idx_1\"].values,\n",
    "        result_df[\"residue_idx_2\"].values,\n",
    "        result_df[\"distance\"].values,\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = extract_seq_and_adj(STRUCTURE_FILE, 'A')\n",
    "print(pdata)\n",
    "print(len(pdata.sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def design_protein_old(net, x, edge_index, edge_attr, results, x_proba=None, cutoff=-0.7):\n",
    "    if x_proba is None:\n",
    "        x_proba = torch.zeros_like(x).to(torch.float)\n",
    "\n",
    "    mask = x == 20\n",
    "    if not mask.any():\n",
    "        if (len(results) + 1) % 100 == 0:\n",
    "            print(f\"Num. results: {len(results) + 1}\", flush=True)\n",
    "        results.append((x, x_proba))\n",
    "        return\n",
    "\n",
    "    index_array = torch.arange(x.size(0))\n",
    "\n",
    "    output = net(x, edge_index, edge_attr)\n",
    "    output = torch.softmax(output, dim=1)\n",
    "    output = output[mask]\n",
    "    index_array = index_array[mask]\n",
    "\n",
    "    max_proba, max_index = output.max(dim=1)[0].max(dim=0)\n",
    "    row_with_max_proba = output[max_index]\n",
    "\n",
    "    sum_log_prob = x_proba.sum()\n",
    "    assert sum_log_prob.item() <= 0, x_proba\n",
    "    p_cutoff = min(torch.exp(cutoff * x.size(0) - sum_log_prob), row_with_max_proba.max()).item()\n",
    "\n",
    "    for i, p in enumerate(row_with_max_proba):\n",
    "        if p < p_cutoff:\n",
    "            continue\n",
    "        x_clone = x.clone()\n",
    "        x_proba_clone = x_proba.clone()\n",
    "        assert x_clone[index_array[max_index]] == 20\n",
    "        assert x_proba_clone[index_array[max_index]] == 0\n",
    "        x_clone[index_array[max_index]] = i\n",
    "        x_proba_clone[index_array[max_index]] = torch.log(p)\n",
    "        design_protein(net, x_clone, edge_index, edge_attr, results=results, x_proba=x_proba_clone, cutoff=cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@dataclass(order=True)\n",
    "class PrioritizedItem:\n",
    "    p: float\n",
    "    x: Any = field(compare=False)\n",
    "    x_proba: Any = field(compare=False)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_descendents(net, x, x_proba, edge_index, edge_attr, cutoff):\n",
    "    index_array = torch.arange(x.size(0))\n",
    "    mask = x == 20\n",
    "\n",
    "    output = net(x, edge_index, edge_attr)\n",
    "    output = torch.softmax(output, dim=1)\n",
    "    output = output[mask]\n",
    "    index_array = index_array[mask]\n",
    "\n",
    "    max_proba, max_index = output.max(dim=1)[0].max(dim=0)\n",
    "    row_with_max_proba = output[max_index]\n",
    "\n",
    "    sum_log_prob = x_proba.sum()\n",
    "    assert sum_log_prob.item() <= 0, x_proba\n",
    "#     p_cutoff = min(torch.exp(sum_log_prob), row_with_max_proba.max()).item()\n",
    "\n",
    "    children = []\n",
    "    for i, p in enumerate(row_with_max_proba):\n",
    "#         if p < p_cutoff:\n",
    "#             continue\n",
    "        x_clone = x.clone()\n",
    "        x_proba_clone = x_proba.clone()\n",
    "        assert x_clone[index_array[max_index]] == 20\n",
    "        assert x_proba_clone[index_array[max_index]] == cutoff\n",
    "        x_clone[index_array[max_index]] = i\n",
    "        x_proba_clone[index_array[max_index]] = torch.log(p)\n",
    "        children.append((x_clone, x_proba_clone))\n",
    "    return children\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def design_protein(net, x, edge_index, edge_attr, results, cutoff):\n",
    "    x_proba = torch.ones_like(x).to(torch.float) * cutoff\n",
    "    heap = [PrioritizedItem(0, x, x_proba)]\n",
    "    i = 0\n",
    "    while heap:\n",
    "        item = heapq.heappop(heap)\n",
    "        if i % 1000 == 0:\n",
    "            print(\n",
    "                f\"i: {i}; p: {item.p:.4f}; num missing: {(item.x == 20).sum()}; \"\n",
    "                f\"heap size: {len(heap):7d}; results size: {len(results)}\"\n",
    "            )\n",
    "        if not (item.x == 20).any():\n",
    "            results.append(item)\n",
    "        else:\n",
    "            children = get_descendents(net, item.x, item.x_proba, edge_index, edge_attr, cutoff)\n",
    "            for x, x_proba in children:\n",
    "                heapq.heappush(heap, PrioritizedItem(-x_proba.sum(), x, x_proba))\n",
    "        i += 1\n",
    "        if len(heap) > 1_000_000:\n",
    "            heap = heap[:700_000]\n",
    "            heapq.heapify(heap)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_protein_proba(net, x_ref, edge_index, edge_attr):\n",
    "    x = torch.ones_like(x_ref) * 20\n",
    "    x_proba = torch.zeros_like(x_ref).to(torch.float)\n",
    "    index_array_ref = torch.arange(x_ref.size(0))\n",
    "    mask = x == 20\n",
    "    while mask.any():\n",
    "        output = net(x, edge_index, edge_attr)\n",
    "        output = torch.softmax(output, dim=1)\n",
    "        output_for_x = output.gather(1, x_ref.view(-1, 1))\n",
    "\n",
    "        output_for_x = output_for_x[mask]\n",
    "        index_array = index_array_ref[mask]\n",
    "        max_proba, max_proba_position = output_for_x.max(dim=0)\n",
    "\n",
    "        assert x[index_array[max_proba_position]] == 20\n",
    "        assert x_proba[index_array[max_proba_position]] == 0\n",
    "        x[index_array[max_proba_position]] = x_ref[index_array[max_proba_position]]\n",
    "        x_proba[index_array[max_proba_position]] = torch.log(max_proba)\n",
    "        mask = x == 20\n",
    "    return x_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = proteinsolver.datasets.protein.row_to_data(pdata)\n",
    "data = proteinsolver.datasets.protein.transform_edge_attr(data)\n",
    "data.to(device)\n",
    "\n",
    "get_protein_proba(net, data.x, data.edge_index, data.edge_attr).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = proteinsolver.datasets.protein.row_to_data(pdata)\n",
    "data = proteinsolver.datasets.protein.transform_edge_attr(data)\n",
    "data.to(device)\n",
    "\n",
    "data.y = data.x\n",
    "x_in = torch.ones_like(data.x) * 20\n",
    "results = []\n",
    "design_protein(net, x_in, data.edge_index, data.edge_attr, results=results, cutoff=np.log(0.15))\n",
    "# identity_all = float((y == data.y).sum()) / data.y.size(0)\n",
    "# identity_missing = float((y[~is_present] == data.y[~is_present]).sum()) / (~is_present).sum().item()\n",
    "# result = {\"identity_all\": identity_all, \"identity_missing\": identity_missing}\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(results, NOTEBOOK_PATH / (STRUCTURE_FILE.stem + \".torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1fXJz1l9HvhW",
    "u9q4iTifHvhl"
   ],
   "name": "Copy of 2019-03-30-sudoku-4xEdgeConv-09862+.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
