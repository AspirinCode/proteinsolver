{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "HCWw1IgNHvhm",
    "outputId": "fcb1a352-1ca8-4708-c3af-11bb0f9a3c57"
   },
   "source": [
    "## Summary\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "- `SEQUENCE_GENERATION_METHOD`\n",
    "- `STRUCTURE_ID`\n",
    "- `SLURM_ARRAY_TASK_ID`\n",
    "\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- `astar` method should be given >= 64G memory in order to generate 200k sequences.\n",
    "- `astar` cannot be ran in parallel.\n",
    "\n",
    "**SLURM scripts**\n",
    "\n",
    "```bash\n",
    "STRUCTURE_ID=\"4unuA00\" SEQUENCE_GENERATION_METHOD=\"astar\" sbatch --mem 64G --time 72:00:00 ./scripts/run_notebook_gpu.sh \\\n",
    "    $(realpath ./notebooks/10_generate_protein_sequence.ipynb)\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "STRUCTURE_ID=\"4unuA00\" SEQUENCE_GENERATION_METHOD=\"expectimax\" sbatch --mem 32G --time 24:00:00 --array=1-10 ./scripts/run_notebook_gpu.sh \\\n",
    "    $(realpath ./notebooks/10_generate_protein_sequence.ipynb)\n",
    "```\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoBMUoW2Hvhp",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/strokach/env/lib/python3.7/site-packages/Bio/KDTree/__init__.py:25: BiopythonDeprecationWarning: Bio.KDTree has been deprecated, and we intend to remove it in a future release of Biopython. Please use Bio.PDB.kdtrees instead, which is functionally very similar.\n",
      "  BiopythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import heapq\n",
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import kmtools.sci_tools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import proteinsolver\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch_geometric\n",
    "from kmbio import PDB\n",
    "from torch_geometric.data import Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = \"generate_protein_sequences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kimlab1/strokach/workspace/proteinsolver/notebooks/generate_protein_sequences')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTEBOOK_PATH = Path(NOTEBOOK_NAME).resolve()\n",
    "NOTEBOOK_PATH.mkdir(exist_ok=True)\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_ID = \"191f05de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_STATE_FILES = {\n",
    "    #\n",
    "    \"191f05de\": \"protein_train/191f05de/e53-s1952148-d93703104.state\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure_id = os.getenv(\"STRUCTURE_ID\", \"1n5uA03\")\n",
    "# structure_id = os.getenv(\"STRUCTURE_ID\", \"4z8jA00\")\n",
    "structure_id = os.getenv(\"STRUCTURE_ID\", \"4unuA00\")\n",
    "# structure_id = os.getenv(\"STRUCTURE_ID\", \"4beuA02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/kimlab1/strokach/workspace/proteinsolver/data/inputs/4unuA00.pdb')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STRUCTURE_FILE = Path(\n",
    "    os.getenv(\"STRUCTURE_FILE\", NOTEBOOK_PATH.parent.parent / \"data\" / \"inputs\" / f\"{structure_id}.pdb\")\n",
    ").resolve()\n",
    "STRUCTURE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_expected_proba_preset = {\"1n5uA03\": 0.15, \"4unuA00\": 0.25, \"4beuA02\": 0.25}\n",
    "\n",
    "MIN_EXPECTED_PROBA = min_expected_proba_preset.get(structure_id, 0.15)\n",
    "MIN_EXPECTED_PROBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_GENERATION_METHOD = os.getenv(\"SEQUENCE_GENERATION_METHOD\", \"expectimax\")\n",
    "\n",
    "assert SEQUENCE_GENERATION_METHOD in (\"astar\", \"expectimax\", \"root2expectimax\", \"root10expectimax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_FILE_INDEX = int(os.getenv(\"SLURM_ARRAY_TASK_ID\", 0)) * 1000\n",
    "START_FILE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_all = PDB.load(STRUCTURE_FILE)\n",
    "structure = PDB.Structure(STRUCTURE_FILE.name + \"A\", structure_all[0].extract('A'))\n",
    "assert len(list(structure.chains)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c9837c27b84217a5a8d8bd6c84b50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_ColormakerRegistry()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cfd152acea4ef2b8d7b59e6c598895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = PDB.view_structure(structure)\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3kWuRaxr89h"
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run protein_train/{UNIQUE_ID}/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_features = 20\n",
    "adj_input_size = 2\n",
    "hidden_size = 128\n",
    "frac_present = 0.5\n",
    "frac_present_valid = frac_present\n",
    "info_size= 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'protein_train/191f05de/e53-s1952148-d93703104.state'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_file = BEST_STATE_FILES[UNIQUE_ID]\n",
    "state_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(\n",
    "    x_input_size=num_features + 1, adj_input_size=adj_input_size, hidden_size=hidden_size, output_size=num_features\n",
    ")\n",
    "net.load_state_dict(torch.load(state_file, map_location=device))\n",
    "net.eval()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load protein sequence and geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProteinData(sequence='SALTQPPSASGSLGQSVTISCTGTSSDVGGYNYVSWYQQHAGKAPKVIIYEVNKRPSGVPDRFSGSKSGNTASLTVSGLQAEDEADYYCSSYEGSDNFVFGTGTKVTVL', row_index=array([  0,   0,   0, ..., 106, 106, 107]), col_index=array([  1,   2,   3, ..., 107, 108, 108]), distances=array([1.29767875, 3.76060342, 6.58874989, ..., 1.32708647, 4.12791238,\n",
      "       1.32601478]))\n"
     ]
    }
   ],
   "source": [
    "pdata = proteinsolver.utils.extract_seq_and_adj(STRUCTURE_FILE, 'A')\n",
    "print(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 SALTQPPSASGSLGQSVTISCTGTSSDVGGYNYVSWYQQHAGKAPKVIIYEVNKRPSGVPDRFSGSKSGNTASLTVSGLQAEDEADYYCSSYEGSDNFVFGTGTKVTVL\n"
     ]
    }
   ],
   "source": [
    "sequence_ref = pdata.sequence\n",
    "print(len(sequence_ref), sequence_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to suitable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-187.21701049804688"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = proteinsolver.datasets.protein.row_to_data(pdata)\n",
    "data = proteinsolver.datasets.protein.transform_edge_attr(data)\n",
    "data.to(device)\n",
    "\n",
    "proteinsolver.utils.get_node_proba(net, data.x, data.edge_index, data.edge_attr).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def design_sequence(net, data, normalize_fn=None, num_categories=None):\n",
    "    if num_categories is None:\n",
    "        num_categories = data.x.max().item()\n",
    "    batch_size = data_batch.batch.max().item() + 1\n",
    "\n",
    "    x = data.x.clone()\n",
    "    x_proba = torch.zeros_like(x).to(torch.float)\n",
    "    index_array_ref = torch.arange(x.size(0))\n",
    "    mask_ref = x == num_categories\n",
    "    while mask_ref.any():\n",
    "        output = net(x, data.edge_index, data.edge_attr)\n",
    "        output_proba_ref = torch.softmax(output, dim=1)\n",
    "        output_proba_max_ref, _ = output_proba_ref.max(dim=1)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            mask = mask_ref & (data.batch == i)\n",
    "\n",
    "            index_array = index_array_ref[mask]\n",
    "\n",
    "            max_probas = output_proba_max_ref[mask]\n",
    "            max_proba_index = index_array[max_probas.argmax().item()]\n",
    "\n",
    "            assert x[max_proba_index] == num_categories, x[max_proba_index]\n",
    "            assert x_proba[max_proba_index] == 0, x_proba[max_proba_index]\n",
    "            category_probas = output_proba_ref[max_proba_index]\n",
    "            if normalize_fn is not None:\n",
    "                category_probas_norm = normalize_fn(category_probas)\n",
    "            else:\n",
    "                category_probas_norm = category_probas\n",
    "            chosen_category = torch.multinomial(category_probas_norm, 1).item()\n",
    "            chosen_category_proba = category_probas[chosen_category]\n",
    "\n",
    "            assert chosen_category != num_categories\n",
    "            x[max_proba_index] = chosen_category\n",
    "            x_proba[max_proba_index] = chosen_category_proba\n",
    "        mask_ref = x == num_categories\n",
    "        del output, output_proba_ref, output_proba_max_ref\n",
    "    return x, x_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from dataclasses import field\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def load_heap_dump(heap_file):\n",
    "    if heap_file.is_file():\n",
    "        try:\n",
    "            return torch.load(heap_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Encountered error loading heap file '{heap_file}': '{e}'.\")\n",
    "\n",
    "    heap_file_bak = heap_file.with_suffix(\".pickle.bak\")\n",
    "    if heap_file_bak.is_file():\n",
    "        try:\n",
    "            return torch.load(heap_file_bak)\n",
    "        except Exception as e:\n",
    "            print(f\"Encountered error loading heap file '{heap_file_bak}': '{e}'.\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def update_heap_dump(heap_file, heap):\n",
    "    try:\n",
    "        shutil.copy2(heap_file, heap_file.with_suffix(\".pickle.bak\"))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    torch.save(heap, heap_file)\n",
    "\n",
    "\n",
    "def get_descendents(net, x, x_proba, edge_index, edge_attr, cutoff):\n",
    "    index_array = torch.arange(x.size(0))\n",
    "    mask = x == 20\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(x.to(device), edge_index.to(device), edge_attr.to(device)).cpu()\n",
    "    output = torch.softmax(output, dim=1)\n",
    "    output = output[mask]\n",
    "    index_array = index_array[mask]\n",
    "\n",
    "    max_proba, max_index = output.max(dim=1)[0].max(dim=0)\n",
    "    row_with_max_proba = output[max_index]\n",
    "\n",
    "    sum_log_prob = x_proba.sum()\n",
    "    assert sum_log_prob.item() <= 0, x_proba\n",
    "    #     p_cutoff = min(torch.exp(sum_log_prob), row_with_max_proba.max()).item()\n",
    "\n",
    "    children = []\n",
    "    for i, p in enumerate(row_with_max_proba):\n",
    "        #         if p < p_cutoff:\n",
    "        #             continue\n",
    "        x_clone = x.clone()\n",
    "        x_proba_clone = x_proba.clone()\n",
    "        assert x_clone[index_array[max_index]] == 20\n",
    "        assert x_proba_clone[index_array[max_index]] == cutoff\n",
    "        x_clone[index_array[max_index]] = i\n",
    "        x_proba_clone[index_array[max_index]] = torch.log(p)\n",
    "        children.append((x_clone, x_proba_clone))\n",
    "    return children\n",
    "\n",
    "\n",
    "def design_sequence_astar(\n",
    "    net, data, cutoff, num_categories=20, max_results=5_000, max_heap_size=10_000_000, heap=None\n",
    "):\n",
    "    x_proba = torch.ones_like(data.x).to(torch.float) * cutoff\n",
    "    if heap is None:\n",
    "        heap = [proteinsolver.utils.PrioritizedItem(0, data.x.cpu(), x_proba.cpu())]\n",
    "    results = []\n",
    "    \n",
    "    pbar = tqdm(total=max_results)\n",
    "    while len(results) < max_results:\n",
    "        try:\n",
    "            item = heapq.heappop(heap)\n",
    "        except IndexError:\n",
    "            break\n",
    "        if not (item.x == num_categories).any():\n",
    "            results.append((item.x.data, item.x_proba.exp().sum().item(), item.x_proba.sum().item()))\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            children = get_descendents(net, item.x, item.x_proba, data.edge_index, data.edge_attr, cutoff)\n",
    "            for x, x_proba in children:\n",
    "                heapq.heappush(\n",
    "                    heap, proteinsolver.utils.PrioritizedItem(-x_proba.sum().item(), x.to(\"cpu\"), x_proba.to(\"cpu\"))\n",
    "                )\n",
    "        if len(heap) > max_heap_size:\n",
    "            heap = heap[: len(heap) // 2]\n",
    "            heapq.heapify(heap)\n",
    "    return results, heap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run protein design using expectimax search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[4684, 2], edge_index=[2, 4684], x=[109])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = proteinsolver.datasets.protein.row_to_data(pdata)\n",
    "data = proteinsolver.datasets.protein.transform_edge_attr(data)\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = proteinsolver.utils.AMINO_ACIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_file(file_index):\n",
    "    return NOTEBOOK_PATH.joinpath(f\"designs-{SEQUENCE_GENERATION_METHOD}-{STRUCTURE_FILE.stem}-{file_index}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_index = START_FILE_INDEX\n",
    "\n",
    "while get_output_file(file_index).is_file():\n",
    "    file_index += 1\n",
    "    \n",
    "file_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEQUENCE_GENERATION_METHOD == \"astar\":\n",
    "    data.y = data.x\n",
    "    data.x = torch.ones_like(data.x) * 20\n",
    "\n",
    "    heap_file = NOTEBOOK_PATH.joinpath(f\"heap-{STRUCTURE_FILE.stem}.pickle\")\n",
    "    #     heap = load_heap_dump(heap_file)\n",
    "    heap = None\n",
    "\n",
    "    while True:\n",
    "        results, heap = design_sequence_astar(\n",
    "            net, data, cutoff=np.log(MIN_EXPECTED_PROBA), num_categories=20, max_results=20_000, heap=heap\n",
    "        )\n",
    "        print(len(heap))\n",
    "        #         update_heap_dump(heap_file, heap)\n",
    "        results = [(\"\".join(amino_acids[i] for i in r[0]),) + r[1:] for r in results]\n",
    "        df = pd.DataFrame(results, columns=[\"sequence\", \"probas_sum\", \"probas_log_sum\"])\n",
    "        table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "        pq.write_table(table, get_output_file(file_index))\n",
    "        file_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expectimax None\n",
      "batch_size: 397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c13d6a14bde480c9aeceb7519ad615a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='0', max=13, style=ProgressStyle(description_width='initial'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-17347a2db442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5_000\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mbatch_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesign_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/strokach/env/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-139426f1d541>\u001b[0m in \u001b[0;36mdesign_sequence\u001b[0;34m(net, data, normalize_fn, num_categories)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_ref\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_array_ref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mmax_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_proba_max_ref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if SEQUENCE_GENERATION_METHOD.endswith(\"expectimax\"):\n",
    "\n",
    "    if SEQUENCE_GENERATION_METHOD == \"root2expectimax\":\n",
    "        root = 2\n",
    "    elif SEQUENCE_GENERATION_METHOD == \"root10expectimax\":\n",
    "        root = 10\n",
    "    else:\n",
    "        root = None\n",
    "\n",
    "    print(SEQUENCE_GENERATION_METHOD, root)\n",
    "    normalize_fn = (lambda proba: proba ** (1 / root)) if root is not None else None\n",
    "\n",
    "    batch_size = int(512 * (92 / len(sequence_ref)) ** 1.5)\n",
    "    print(f\"batch_size: {batch_size}\")\n",
    "\n",
    "    data_batch = Batch.from_data_list([data.clone() for _ in range(batch_size)]).to(device)\n",
    "    data_batch.x = torch.ones_like(data_batch.x) * 20\n",
    "\n",
    "    while True:\n",
    "        results = []\n",
    "        for _ in tqdm(range(int(np.ceil(5_000 / batch_size))), desc=str(file_index)):\n",
    "            batch_values, batch_probas = design_sequence(net, data_batch, normalize_fn=normalize_fn)\n",
    "            for i in range(batch_size):\n",
    "                values = batch_values[data_batch.batch == i]\n",
    "                probas = batch_probas[data_batch.batch == i]\n",
    "                sequence = \"\".join(amino_acids[i] for i in values)\n",
    "                probas_sum = probas.sum().item()\n",
    "                probas_log_sum = probas.log().sum().item()\n",
    "                results.append((sequence, probas_sum, probas_log_sum))\n",
    "        df = pd.DataFrame(results, columns=[\"sequence\", \"probas_sum\", \"probas_log_sum\"])\n",
    "        table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "        pq.write_table(table, get_output_file(file_index))\n",
    "        file_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1fXJz1l9HvhW",
    "u9q4iTifHvhl"
   ],
   "name": "Copy of 2019-03-30-sudoku-4xEdgeConv-09862+.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
